{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "name": "COMP8740-NEURAL_NETWORK.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "601fb1b5"
      },
      "source": [
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2"
      ],
      "id": "601fb1b5",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fd8490e8"
      },
      "source": [
        "from os.path import exists\n",
        "\n",
        "def downloadDataset():\n",
        "  !wget http://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
        "  !unzip -q tiny-imagenet-200.zip && ls tiny-imagenet-200\n",
        "\n",
        "is_exists = exists('tiny-imagenet-200.zip')\n",
        "if not is_exists:\n",
        "  downloadDataset()"
      ],
      "id": "fd8490e8",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6d5889ad"
      },
      "source": [
        "def mapDirectoryToInt():\n",
        "  ID_DICT = {}\n",
        "  PATH = 'tiny-imagenet-200/wnids.txt'\n",
        "  FILEOPEN = open(PATH,'r')\n",
        "  for i, folder in enumerate(FILEOPEN):\n",
        "    ID_DICT[folder.replace('\\n','')]=i\n",
        "  return ID_DICT\n",
        "\n",
        "ID_DICT = mapDirectoryToInt()"
      ],
      "id": "6d5889ad",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50f15d47"
      },
      "source": [
        "def getImage(folderName=None):\n",
        "    DATASET_PATH = 'tiny-imagenet-200/'+folderName+'/'\n",
        "    directories = os.listdir(DATASET_PATH)\n",
        "    ONE_HOT_ENCODED = np.eye(len(directories))\n",
        "    MAP_DIC = mapDirectoryToInt()\n",
        "    TRAIN_IMAGES = []\n",
        "    TRAIN_LABELS = []\n",
        "    CLASS = None\n",
        "    for directory in directories:\n",
        "        path = DATASET_PATH+directory+'/'\n",
        "        files = os.listdir(path)\n",
        "        if files[0].endswith('.txt'):\n",
        "            CLASS = files[0]\n",
        "        else:\n",
        "            CLASS = files[1]\n",
        "        for file in files:\n",
        "            if file.endswith('.txt'):\n",
        "                continue\n",
        "            IMG_FOLDER_PATH = path+file+'/'\n",
        "            IMAGES = os.listdir(IMG_FOLDER_PATH)\n",
        "            for IMAGE in IMAGES:\n",
        "                IMG_PATH = IMG_FOLDER_PATH+IMAGE\n",
        "                img = cv2.imread(IMG_PATH)\n",
        "                if len(img.shape)< 3:\n",
        "                    continue\n",
        "                #img = np.reshape(img,[64,64,3])\n",
        "                TRAIN_IMAGES.append(img)\n",
        "                TRAIN_LABELS.append((np.reshape(ONE_HOT_ENCODED[MAP_DIC[CLASS.replace('_boxes.txt','')]], [200])))\n",
        "    return np.array(TRAIN_IMAGES), np.array(TRAIN_LABELS)"
      ],
      "id": "50f15d47",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57a70a8b"
      },
      "source": [
        "def loadValidationData(folderName=None):\n",
        "  DATASET_PATH = 'tiny-imagenet-200/'\n",
        "  DATASET_FILE_PATH = 'tiny-imagenet-200/'+folderName+'/val_annotations.txt'\n",
        "  ONE_HOT_ENCODED = np.eye(200)\n",
        "  MAP_DIC = mapDirectoryToInt()\n",
        "  file = open(DATASET_FILE_PATH)\n",
        "  TEST = []\n",
        "  TEST_LABELS = []\n",
        "  cnt = 0\n",
        "  for line in file:\n",
        "    image, class_id = line.split('\\t')[:2]\n",
        "    IMG_PATH = DATASET_PATH+folderName+'/images/'+image\n",
        "    img = cv2.imread(IMG_PATH)\n",
        "    if len(img.shape) <3:\n",
        "      continue\n",
        "    TEST.append(img)\n",
        "    TEST_LABELS.append((np.reshape(ONE_HOT_ENCODED[MAP_DIC[class_id]], [200])))\n",
        "  return np.array(TEST), np.array(TEST_LABELS)"
      ],
      "id": "57a70a8b",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "un5HeLboFqsU",
        "outputId": "d316025c-0471-4b05-fea8-d5113737d24f"
      },
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "TRAIN_IMAGES, TRAIN_LABELS = getImage('train')\n",
        "TEST_IMAGES, TEST_LABELS = loadValidationData('val')\n",
        "\n",
        "\n",
        "TEST_IMAGES = keras.applications.resnet50.preprocess_input(TEST_IMAGES)\n",
        "TRAIN_IMAGES =  keras.applications.resnet50.preprocess_input(TRAIN_IMAGES)\n",
        "\n",
        "print(TRAIN_IMAGES.shape)\n",
        "print(TRAIN_LABELS.shape)\n",
        "\n",
        "print(TEST_IMAGES.shape)\n",
        "print(TEST_LABELS.shape)"
      ],
      "id": "un5HeLboFqsU",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100000, 64, 64, 3)\n",
            "(100000, 200)\n",
            "(10000, 64, 64, 3)\n",
            "(10000, 200)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NKK9IyeL4Yn",
        "outputId": "4f12532e-159f-4f11-9100-85255959b838"
      },
      "source": [
        "!pip install hyperas"
      ],
      "id": "4NKK9IyeL4Yn",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting hyperas\n",
            "  Downloading hyperas-0.4.1-py3-none-any.whl (9.1 kB)\n",
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.7/dist-packages (from hyperas) (0.1.2)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from hyperas) (5.6.1)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from hyperas) (2.7.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from hyperas) (0.3)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.7/dist-packages (from hyperas) (1.0.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from hyperas) (5.1.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from hyperopt->hyperas) (0.16.0)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.7/dist-packages (from hyperopt->hyperas) (3.12.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from hyperopt->hyperas) (1.4.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from hyperopt->hyperas) (2.6.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from hyperopt->hyperas) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from hyperopt->hyperas) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from hyperopt->hyperas) (4.62.3)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from jupyter->hyperas) (7.6.5)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from jupyter->hyperas) (4.10.1)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter->hyperas) (5.2.0)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter->hyperas) (5.3.1)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter->hyperas) (5.2.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->hyperas) (5.3.5)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->hyperas) (5.1.1)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->hyperas) (5.5.0)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->hyperas) (5.1.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->hyperas) (57.4.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->hyperas) (0.8.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->hyperas) (2.6.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->hyperas) (4.4.2)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->hyperas) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->hyperas) (1.0.18)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->hyperas) (0.7.5)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->jupyter->hyperas) (0.2.5)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->hyperas) (3.5.2)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->hyperas) (0.2.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->hyperas) (1.0.2)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat->hyperas) (2.6.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat->hyperas) (4.9.1)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->hyperas) (0.12.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->hyperas) (2.11.3)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->hyperas) (1.8.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel->jupyter->hyperas) (2.8.2)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel->jupyter->hyperas) (22.3.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter->hyperas) (0.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook->jupyter->hyperas) (2.0.1)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->hyperas) (0.5.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->hyperas) (4.1.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->hyperas) (1.5.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->hyperas) (0.7.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->hyperas) (0.8.4)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->hyperas) (0.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->hyperas) (21.2)\n",
            "Requirement already satisfied: pyparsing<3,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->bleach->nbconvert->hyperas) (2.4.7)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->hyperas) (1.11.2)\n",
            "Installing collected packages: hyperas\n",
            "Successfully installed hyperas-0.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41YWRtPVHfai"
      },
      "source": [
        "from hyperas import optim\n",
        "\n",
        "def model(x_train, y_train, x_test, y_test):\n",
        "    \"\"\"\n",
        "    Model providing function:\n",
        "\n",
        "    Create Keras model with double curly brackets dropped-in as needed.\n",
        "    Return value has to be a valid python dictionary with two customary keys:\n",
        "        - loss: Specify a numeric evaluation metric to be minimized\n",
        "        - status: Just use STATUS_OK and see hyperopt documentation if not feasible\n",
        "    The last one is optional, though recommended, namely:\n",
        "        - model: specify the model just created so that we can later use it again.\n",
        "    \"\"\"\n",
        "    input_shape = K.Input(shape=(64,64,3))\n",
        "\n",
        "    model_mlp = Sequential()\n",
        "    model_mlp.add(Dense({{choice([32, 64,126, 256, 512, 1024])}},\n",
        "                        activation='relu', input_shape= input_shape))\n",
        "    model_mlp.add(Dropout({{uniform(0, .5)}}))\n",
        "    model_mlp.add(Dense({{choice([32, 64, 126, 256, 512, 1024])}}))\n",
        "    model_mlp.add(Activation({{choice(['relu', 'sigmoid'])}}))\n",
        "    model_mlp.add(Dropout({{uniform(0, .5)}}))\n",
        "    model_mlp.add(Dense({{choice([32, 64, 126, 256, 512, 1024])}}))\n",
        "    model_mlp.add(Activation({{choice(['relu', 'sigmoid'])}}))\n",
        "    model_mlp.add(Dropout({{uniform(0, .5)}}))\n",
        "    model_mlp.add(Dense({{choice([32, 64, 126, 256, 512, 1024])}}))\n",
        "    model_mlp.add(Activation({{choice(['relu', 'sigmoid'])}}))\n",
        "    model_mlp.add(Dropout({{uniform(0, .5)}}))\n",
        "    model_mlp.add(Dense(200))\n",
        "    model_mlp.add(Activation({{choice(['softmax','linear'])}}))\n",
        "    model_mlp.compile(loss={{choice(['categorical_crossentropy','mse'])}}, metrics=['accuracy'],\n",
        "                  optimizer={{choice(['rmsprop', 'adam', 'sgd'])}})\n",
        "\n",
        "\n",
        "model = model()\n",
        "model.fit(TRAIN_IMAGES, TRAIN_LABELS,\n",
        "          batch_size={{choice([16, 32, 64, 128])}},\n",
        "          epochs=2,\n",
        "          verbose=2,\n",
        "          validation_data=(x_test, y_test))\n",
        "score, acc = model_mlp.evaluate(TEST_IMAGES, TEST_LABELS, verbose=1)\n",
        "print('Test accuracy:', acc)\n",
        "return {'loss': -acc, 'status': STATUS_OK, 'model': model_mlp}"
      ],
      "id": "41YWRtPVHfai",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHAXBxSFHTIp"
      },
      "source": [
        " best_run, best_model = optim.minimize(model=model,\n",
        "                                              data=data,\n",
        "                                              algo=tpe.suggest,\n",
        "                                              max_evals=2,\n",
        "                                              trials=Trials())\n",
        "        X_train, Y_train, X_test, Y_test = data()\n",
        "        print(\"Evalutation of best performing model:\")\n",
        "        print(best_model.evaluate(X_test, Y_test))\n",
        "        print(\"Best performing model chosen hyper-parameters:\")\n",
        "        print(best_run)"
      ],
      "id": "hHAXBxSFHTIp",
      "execution_count": null,
      "outputs": []
    }
  ]
}